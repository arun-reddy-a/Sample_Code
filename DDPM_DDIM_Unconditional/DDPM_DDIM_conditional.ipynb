{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from labml_nn.diffusion.stable_diffusion.model.unet_attention import SpatialTransformer\n",
    "from tqdm import tqdm\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetModel(nn.Module):\n",
    "    \"\"\"\n",
    "    ## U-Net model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, *,\n",
    "            in_channels: int,\n",
    "            out_channels: int,\n",
    "            channels: int,\n",
    "            n_res_blocks: int,\n",
    "            attention_levels: List[int],\n",
    "            channel_multipliers: List[int],\n",
    "            n_heads: int,\n",
    "            tf_layers: int = 1,\n",
    "            d_cond: int = 768):\n",
    "        \"\"\"\n",
    "        :param in_channels: is the number of channels in the input feature map\n",
    "        :param out_channels: is the number of channels in the output feature map\n",
    "        :param channels: is the base channel count for the model\n",
    "        :param n_res_blocks: number of residual blocks at each level\n",
    "        :param attention_levels: are the levels at which attention should be performed\n",
    "        :param channel_multipliers: are the multiplicative factors for number of channels for each level\n",
    "        :param n_heads: is the number of attention heads in the transformers\n",
    "        :param tf_layers: is the number of transformer layers in the transformers\n",
    "        :param d_cond: is the size of the conditional embedding in the transformers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "\n",
    "        # Number of levels\n",
    "        levels = len(channel_multipliers)\n",
    "        # Size time embeddings\n",
    "        d_time_emb = channels * 4\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(channels, d_time_emb),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(d_time_emb, d_time_emb),\n",
    "        )\n",
    "\n",
    "        # Input half of the U-Net\n",
    "        self.input_blocks = nn.ModuleList()\n",
    "        # Initial $3 \\times 3$ convolution that maps the input to `channels`.\n",
    "        # The blocks are wrapped in `TimestepEmbedSequential` module because\n",
    "        # different modules have different forward function signatures;\n",
    "        # for example, convolution only accepts the feature map and\n",
    "        # residual blocks accept the feature map and time embedding.\n",
    "        # `TimestepEmbedSequential` calls them accordingly.\n",
    "        self.input_blocks.append(TimestepEmbedSequential(\n",
    "            nn.Conv2d(in_channels, channels, 3, padding=1)))\n",
    "        # Number of channels at each block in the input half of U-Net\n",
    "        input_block_channels = [channels]\n",
    "        # Number of channels at each level\n",
    "        channels_list = [channels * m for m in channel_multipliers]\n",
    "        # Prepare levels\n",
    "        for i in range(levels):\n",
    "            # Add the residual blocks and attentions\n",
    "            for _ in range(n_res_blocks):\n",
    "                # Residual block maps from previous number of channels to the number of\n",
    "                # channels in the current level\n",
    "                layers = [ResBlock(channels, d_time_emb, out_channels=channels_list[i])]\n",
    "                channels = channels_list[i]\n",
    "                # Add transformer\n",
    "                if i in attention_levels:\n",
    "                    layers.append(SpatialTransformer(channels, n_heads, tf_layers, d_cond))\n",
    "                # Add them to the input half of the U-Net and keep track of the number of channels of\n",
    "                # its output\n",
    "                self.input_blocks.append(TimestepEmbedSequential(*layers))\n",
    "                input_block_channels.append(channels)\n",
    "            # Down sample at all levels except last\n",
    "            if i != levels - 1:\n",
    "                self.input_blocks.append(TimestepEmbedSequential(DownSample(channels)))\n",
    "                input_block_channels.append(channels)\n",
    "\n",
    "        # The middle of the U-Net\n",
    "        self.middle_block = TimestepEmbedSequential(\n",
    "            ResBlock(channels, d_time_emb),\n",
    "            SpatialTransformer(channels, n_heads, tf_layers, d_cond),\n",
    "            ResBlock(channels, d_time_emb),\n",
    "        )\n",
    "\n",
    "        # Second half of the U-Net\n",
    "        self.output_blocks = nn.ModuleList([])\n",
    "        # Prepare levels in reverse order\n",
    "        for i in reversed(range(levels)):\n",
    "            # Add the residual blocks and attentions\n",
    "            for j in range(n_res_blocks + 1):\n",
    "                # Residual block maps from previous number of channels plus the\n",
    "                # skip connections from the input half of U-Net to the number of\n",
    "                # channels in the current level.\n",
    "                layers = [ResBlock(channels + input_block_channels.pop(), d_time_emb, out_channels=channels_list[i])]\n",
    "                channels = channels_list[i]\n",
    "                # Add transformer\n",
    "                if i in attention_levels:\n",
    "                    layers.append(SpatialTransformer(channels, n_heads, tf_layers, d_cond))\n",
    "                # Up-sample at every level after last residual block\n",
    "                # except the last one.\n",
    "                # Note that we are iterating in reverse; i.e. `i == 0` is the last.\n",
    "                if i != 0 and j == n_res_blocks:\n",
    "                    layers.append(UpSample(channels))\n",
    "                # Add to the output half of the U-Net\n",
    "                self.output_blocks.append(TimestepEmbedSequential(*layers))\n",
    "\n",
    "        # Final normalization and $3 \\times 3$ convolution\n",
    "        self.out = nn.Sequential(\n",
    "            normalization(channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(channels, out_channels, 3, padding=1),\n",
    "        )\n",
    "\n",
    "    def time_step_embedding(self, time_steps: torch.Tensor, max_period: int = 10000):\n",
    "        \"\"\"\n",
    "        ## Create sinusoidal time step embeddings\n",
    "\n",
    "        :param time_steps: are the time steps of shape `[batch_size]`\n",
    "        :param max_period: controls the minimum frequency of the embeddings.\n",
    "        \"\"\"\n",
    "        # $\\frac{c}{2}$; half the channels are sin and the other half is cos,\n",
    "        half = self.channels // 2\n",
    "        # $\\frac{1}{10000^{\\frac{2i}{c}}}$\n",
    "        frequencies = torch.exp(\n",
    "            -math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half\n",
    "        ).to(device=time_steps.device)\n",
    "        # $\\frac{t}{10000^{\\frac{2i}{c}}}$\n",
    "        args = time_steps[:, None].float() * frequencies[None]\n",
    "        # $\\cos\\Bigg(\\frac{t}{10000^{\\frac{2i}{c}}}\\Bigg)$ and $\\sin\\Bigg(\\frac{t}{10000^{\\frac{2i}{c}}}\\Bigg)$\n",
    "        return torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, time_steps: torch.Tensor, cond: torch.Tensor):\n",
    "        \"\"\"\n",
    "        :param x: is the input feature map of shape `[batch_size, channels, width, height]`\n",
    "        :param time_steps: are the time steps of shape `[batch_size]`\n",
    "        :param cond: conditioning of shape `[batch_size, n_cond, d_cond]`\n",
    "        \"\"\"\n",
    "        # To store the input half outputs for skip connections\n",
    "        x_input_block = []\n",
    "\n",
    "        # Get time step embeddings\n",
    "        t_emb = self.time_step_embedding(time_steps)\n",
    "        t_emb = self.time_embed(t_emb)\n",
    "\n",
    "        # Input half of the U-Net\n",
    "        for module in self.input_blocks:\n",
    "            x = module(x, t_emb, cond)\n",
    "            x_input_block.append(x)\n",
    "        # Middle of the U-Net\n",
    "        x = self.middle_block(x, t_emb, cond)\n",
    "        # Output half of the U-Net\n",
    "        for module in self.output_blocks:\n",
    "            x = torch.cat([x, x_input_block.pop()], dim=1)\n",
    "            x = module(x, t_emb, cond)\n",
    "\n",
    "        # Final normalization and $3 \\times 3$ convolution\n",
    "        return self.out(x)\n",
    "\n",
    "\n",
    "class TimestepEmbedSequential(nn.Sequential):\n",
    "    \"\"\"\n",
    "    ### Sequential block for modules with different inputs\n",
    "\n",
    "    This sequential module can compose of different modules such as `ResBlock`,\n",
    "    `nn.Conv` and `SpatialTransformer` and calls them with the matching signatures\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x, t_emb, cond=None):\n",
    "        for layer in self:\n",
    "            if isinstance(layer, ResBlock):\n",
    "                x = layer(x, t_emb)\n",
    "            elif isinstance(layer, SpatialTransformer):\n",
    "                x = layer(x, cond)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    \"\"\"\n",
    "    ### Up-sampling layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int):\n",
    "        \"\"\"\n",
    "        :param channels: is the number of channels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # $3 \\times 3$ convolution mapping\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        :param x: is the input feature map with shape `[batch_size, channels, height, width]`\n",
    "        \"\"\"\n",
    "        # Up-sample by a factor of $2$\n",
    "        x = F.interpolate(x, scale_factor=2, mode=\"nearest\")\n",
    "        # Apply convolution\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    \"\"\"\n",
    "    ## Down-sampling layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int):\n",
    "        \"\"\"\n",
    "        :param channels: is the number of channels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # $3 \\times 3$ convolution with stride length of $2$ to down-sample by a factor of $2$\n",
    "        self.op = nn.Conv2d(channels, channels, 3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        :param x: is the input feature map with shape `[batch_size, channels, height, width]`\n",
    "        \"\"\"\n",
    "        # Apply convolution\n",
    "        return self.op(x)\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ## ResNet Block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, d_t_emb: int, *, out_channels=None):\n",
    "        \"\"\"\n",
    "        :param channels: the number of input channels\n",
    "        :param d_t_emb: the size of timestep embeddings\n",
    "        :param out_channels: is the number of out channels. defaults to `channels.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # `out_channels` not specified\n",
    "        if out_channels is None:\n",
    "            out_channels = channels\n",
    "\n",
    "        # First normalization and convolution\n",
    "        self.in_layers = nn.Sequential(\n",
    "            normalization(channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(channels, out_channels, 3, padding=1),\n",
    "        )\n",
    "\n",
    "        # Time step embeddings\n",
    "        self.emb_layers = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(d_t_emb, out_channels),\n",
    "        )\n",
    "        # Final convolution layer\n",
    "        self.out_layers = nn.Sequential(\n",
    "            normalization(out_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        )\n",
    "\n",
    "        # `channels` to `out_channels` mapping layer for residual connection\n",
    "        if out_channels == channels:\n",
    "            self.skip_connection = nn.Identity()\n",
    "        else:\n",
    "            self.skip_connection = nn.Conv2d(channels, out_channels, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t_emb: torch.Tensor):\n",
    "        \"\"\"\n",
    "        :param x: is the input feature map with shape `[batch_size, channels, height, width]`\n",
    "        :param t_emb: is the time step embeddings of shape `[batch_size, d_t_emb]`\n",
    "        \"\"\"\n",
    "        # Initial convolution\n",
    "        h = self.in_layers(x)\n",
    "        # Time step embeddings\n",
    "        t_emb = self.emb_layers(t_emb).type(h.dtype)\n",
    "        # Add time step embeddings\n",
    "        h = h + t_emb[:, :, None, None]\n",
    "        # Final convolution\n",
    "        h = self.out_layers(h)\n",
    "        # Add skip connection\n",
    "        return self.skip_connection(x) + h\n",
    "\n",
    "\n",
    "class GroupNorm32(nn.GroupNorm):\n",
    "    \"\"\"\n",
    "    ### Group normalization with float32 casting\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return super().forward(x.float()).type(x.dtype)\n",
    "\n",
    "\n",
    "def normalization(channels):\n",
    "    \"\"\"\n",
    "    ### Group normalization\n",
    "\n",
    "    This is a helper function, with fixed number of groups..\n",
    "    \"\"\"\n",
    "    return GroupNorm32(32, channels)\n",
    "\n",
    "\n",
    "def _test_time_embeddings():\n",
    "    \"\"\"\n",
    "    Test sinusoidal time step embeddings\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    m = UNetModel(in_channels=1, out_channels=1, channels=320, n_res_blocks=1, attention_levels=[],\n",
    "                  channel_multipliers=[],\n",
    "                  n_heads=1, tf_layers=1, d_cond=1)\n",
    "    te = m.time_step_embedding(torch.arange(0, 1000))\n",
    "    plt.plot(np.arange(1000), te[:, [50, 100, 190, 260]].numpy())\n",
    "    plt.legend([\"dim %d\" % p for p in [50, 100, 190, 260]])\n",
    "    plt.title(\"Time embeddings\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 1\n",
    "out_channels = 1\n",
    "channels = 32\n",
    "n_res_block = 2\n",
    "attention_levels = [1,2]\n",
    "channel_multipliers = [2, 3]\n",
    "n_heads = 2\n",
    "tf_layers = 1\n",
    "d_cond = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNoiseScheduler:\n",
    "    r\"\"\"\n",
    "    Class for the linear noise scheduler that is used in DDPM.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_timesteps, beta_start, beta_end):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        \n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps).to(device)\n",
    "        self.alphas = 1. - self.betas\n",
    "        self.alpha_cum_prod = torch.cumprod(self.alphas, dim=0).to(device)\n",
    "        self.sqrt_alpha_cum_prod = torch.sqrt(self.alpha_cum_prod).to(device)\n",
    "        self.sqrt_one_minus_alpha_cum_prod = torch.sqrt(1 - self.alpha_cum_prod).to(device)\n",
    "        \n",
    "    def add_noise(self, original, noise, t):\n",
    "        r\"\"\"\n",
    "        Forward method for diffusion\n",
    "        :param original: Image on which noise is to be applied\n",
    "        :param noise: Random Noise Tensor (from normal dist)\n",
    "        :param t: timestep of the forward process of shape -> (B,)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        original_shape = original.shape\n",
    "        batch_size = original_shape[0]\n",
    "        \n",
    "        sqrt_alpha_cum_prod = self.sqrt_alpha_cum_prod[t].reshape(batch_size)\n",
    "        sqrt_one_minus_alpha_cum_prod = self.sqrt_one_minus_alpha_cum_prod[t].reshape(batch_size)\n",
    "        \n",
    "        # Reshape till (B,) becomes (B,1,1,1) if image is (B,C,H,W)\n",
    "        for _ in range(len(original_shape)-1):\n",
    "            sqrt_alpha_cum_prod = sqrt_alpha_cum_prod.unsqueeze(-1)\n",
    "        for _ in range(len(original_shape)-1):\n",
    "            sqrt_one_minus_alpha_cum_prod = sqrt_one_minus_alpha_cum_prod.unsqueeze(-1)\n",
    "\n",
    "        # Apply and Return Forward process equation\n",
    "        return (sqrt_alpha_cum_prod.to(original.device) * original\n",
    "                + sqrt_one_minus_alpha_cum_prod.to(original.device) * noise)\n",
    "        \n",
    "    def sample_prev_timestep(self, xt, noise_pred, t):\n",
    "        r\"\"\"\n",
    "            Use the noise prediction by model to get\n",
    "            xt-1 using xt and the nosie predicted\n",
    "        :param xt: current timestep sample\n",
    "        :param noise_pred: model noise prediction\n",
    "        :param t: current timestep we are at\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x0 = (xt - (self.sqrt_one_minus_alpha_cum_prod[t] * noise_pred)) / torch.sqrt(self.alpha_cum_prod[t])\n",
    "        x0 = torch.clamp(x0, -1., 1.)\n",
    "\n",
    "        mean = xt - ((self.betas[t])*noise_pred)/(self.sqrt_one_minus_alpha_cum_prod[t])\n",
    "        mean = mean / torch.sqrt(self.alphas[t])\n",
    "        \n",
    "        if t == 0:\n",
    "            return mean, mean\n",
    "        else:\n",
    "            variance = (1-self.alpha_cum_prod[t-1]) / (1.0 - self.alpha_cum_prod[t])\n",
    "            variance = variance * self.betas[t]\n",
    "            sigma = variance ** 0.5\n",
    "            z = torch.randn(xt.shape).to(xt.device)\n",
    "            \n",
    "            # OR\n",
    "            # variance = self.betas[t]\n",
    "            # sigma = variance ** 0.5\n",
    "            # z = torch.randn(xt.shape).to(xt.device)\n",
    "            return mean + sigma*z, x0\n",
    "\n",
    "    def sample_prev_timestep_ddim (self, xt, noise_pred, t, prev_t):\n",
    "\n",
    "        x0 = (xt - self.sqrt_one_minus_alpha_cum_prod[t]*noise_pred) / torch.sqrt(self.alpha_cum_prod[t])\n",
    "        x0 = torch.clamp(x0, -1., 1.)\n",
    "        xt_prev = self.sqrt_alpha_cum_prod[prev_t] * x0 + self.sqrt_one_minus_alpha_cum_prod[prev_t]*noise_pred\n",
    "        return xt_prev, x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_net_model = UNetModel(in_channels=in_channels, out_channels=out_channels, channels=channels, n_res_blocks=n_res_block,\n",
    "                        attention_levels=attention_levels, channel_multipliers=channel_multipliers, n_heads=n_heads, \n",
    "                        tf_layers=tf_layers, d_cond=d_cond).to(device)\n",
    "ls = LinearNoiseScheduler(1000, 1e-4, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): DownSample(\n",
       "        (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GeGLU(\n",
       "                  (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GeGLU(\n",
       "                  (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): SpatialTransformer(\n",
       "      (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "      (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0): BasicTransformerBlock(\n",
       "          (attn1): CrossAttention(\n",
       "            (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "            (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "            (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn2): CrossAttention(\n",
       "            (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (ff): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): GeGLU(\n",
       "                (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (output_blocks): ModuleList(\n",
       "    (0-1): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GeGLU(\n",
       "                  (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 160, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(160, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(160, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GeGLU(\n",
       "                  (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): UpSample(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 160, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(160, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_net_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reddyanugu/miniconda3/envs/pytorch/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/reddyanugu/miniconda3/envs/pytorch/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 6496449.51it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:05<00:00, 5459.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 46989342.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 339999.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load mnist dataset and make dataloader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding_from_times_batch(times, embedding_dim=512):\n",
    "    \"\"\"\n",
    "    Generate positional embeddings for a batch of different time values.\n",
    "\n",
    "    Parameters:\n",
    "    - times (torch.Tensor): 1D tensor of time values for positional encoding (shape: [B]).\n",
    "    - embedding_dim (int): Dimension of the positional embeddings.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Positional embeddings tensor with shape [B, embedding_dim].\n",
    "    \"\"\"\n",
    "    unique_times, indices = torch.unique(times, return_inverse=True)\n",
    "    indices = indices.to(device)\n",
    "    num_times = len(unique_times)\n",
    "\n",
    "    position = torch.arange(0, num_times).unsqueeze(1).float()\n",
    "    div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() * -(math.log(10000.0) / embedding_dim))\n",
    "\n",
    "    # Compute the sinusoidal positional embeddings\n",
    "    sin_embedding = torch.sin(position * div_term)\n",
    "    cos_embedding = torch.cos(position * div_term)\n",
    "\n",
    "    # Combine the sin and cos embeddings\n",
    "    positional_embedding = torch.cat([sin_embedding, cos_embedding], dim=-1).to(device)\n",
    "\n",
    "    # Repeat positional embeddings for each occurrence of a time\n",
    "    repeated_embedding = positional_embedding[indices]\n",
    "\n",
    "    return repeated_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "optimizer = torch.optim.Adam(u_net_model.parameters(), lr=0.0001)\n",
    "p_uncond = 0.3\n",
    "loss_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:45<15:50, 105.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.020362162962555885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [03:35<14:24, 108.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.022181076928973198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [05:24<12:40, 108.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.016054291278123856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [07:14<10:55, 109.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.010906188748776913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [09:06<09:10, 110.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.015894686803221703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [11:02<07:28, 112.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.015535621903836727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [12:54<05:36, 112.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.014514725655317307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [14:40<03:40, 110.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.0260420273989439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [16:26<01:48, 108.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.014033235609531403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [18:13<00:00, 109.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.01483842357993126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for batch in trainloader:\n",
    "        im = batch[0].to(device)\n",
    "        labels = batch[1].to(device)\n",
    "        t = torch.randint(0, 1000, (32,)).to(device)\n",
    "        # cond = torch.zeros(32, 1, 768).to(device)\n",
    "        cond = positional_encoding_from_times_batch(labels, 768).unsqueeze(1).to(device)\n",
    "        noise = torch.randn(32, 1, 28, 28).to(device)\n",
    "        p = torch.rand(1).item()\n",
    "        if (p<p_uncond):\n",
    "            cond = torch.zeros(32, 1, 768).to(device)\n",
    "        xt = ls.add_noise(im, noise, t).to(device)\n",
    "        noise_pred = u_net_model(xt, t, cond)\n",
    "        loss = F.mse_loss(noise_pred, noise)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_array.append(loss.item())\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): DownSample(\n",
       "        (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GeGLU(\n",
       "                  (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GeGLU(\n",
       "                  (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): SpatialTransformer(\n",
       "      (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "      (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0): BasicTransformerBlock(\n",
       "          (attn1): CrossAttention(\n",
       "            (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "            (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "            (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn2): CrossAttention(\n",
       "            (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (ff): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): GeGLU(\n",
       "                (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (output_blocks): ModuleList(\n",
       "    (0-1): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GeGLU(\n",
       "                  (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 160, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(160, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(160, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GeGLU(\n",
       "                  (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): UpSample(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 160, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(160, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_net_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save parameters\n",
    "torch.save(u_net_model.state_dict(), 'aq_cond.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image (cond, guide_factor, ddim=False, end_timestep=999, skip=10):\n",
    "    # memory_used_values = get_gpu_memory_usage()\n",
    "    # print(\"GPU Memory Usage:\", memory_used_values[1])\n",
    "    xt = torch.randn(100, 1, 28, 28).to(device)\n",
    "    un_cond = torch.zeros(100, 1, 768).to(device)\n",
    "    # memory_used_values = get_gpu_memory_usage()\n",
    "    # print(\"GPU Memory Usage:\", memory_used_values[1])\n",
    "    if ddim:\n",
    "        timestamps = torch.arange(end_timestep, 0, -1*skip)[:, None].to(device)\n",
    "    else:\n",
    "        timestamps = torch.arange(end_timestep, 0, -1)[:, None].to(device)\n",
    "    for t in tqdm(timestamps):\n",
    "        index = torch.where(timestamps == t)[0]\n",
    "        with torch.no_grad():\n",
    "            # noise_pred = u_net_model(xt, t, cond)\n",
    "            noise_pred = (guide_factor+1)*u_net_model(xt, t, cond) - (guide_factor)*u_net_model(xt, t, un_cond)\n",
    "            if ddim:\n",
    "                if (index + 1) != len(timestamps):\n",
    "                    xt, x0 = ls.sample_prev_timestep_ddim(xt, noise_pred, t, timestamps[index+1])\n",
    "            else:\n",
    "                xt, x0 = ls.sample_prev_timestep(xt, noise_pred, t)\n",
    "    return xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate images of 4\n",
    "cond = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]).to(device)\n",
    "cond = positional_encoding_from_times_batch(cond, 768).unsqueeze(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [00:34<00:00, 29.28it/s]\n"
     ]
    }
   ],
   "source": [
    "cond_3 = cond[3].unsqueeze(0).repeat(100, 1, 1)\n",
    "images = generate_image(cond=cond_3, guide_factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a 3x3 grid of subplots\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(8, 8))\n",
    "\n",
    "# Iterate through the images and plot them on the subplots\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(images[i][0, :, :].detach().cpu().numpy(), cmap='gray')\n",
    "    ax.axis('off')  # Hide axes for better visualization\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [00:34<00:00, 29.22it/s]\n"
     ]
    }
   ],
   "source": [
    "cond_9 = cond[9].unsqueeze(0).repeat(100, 1, 1)\n",
    "images = generate_image(cond=cond_9, guide_factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a 3x3 grid of subplots\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(8, 8))\n",
    "\n",
    "# Iterate through the images and plot them on the subplots\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(images[i][0, :, :].detach().cpu().numpy(), cmap='gray')\n",
    "    ax.axis('off')  # Hide axes for better visualization\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
