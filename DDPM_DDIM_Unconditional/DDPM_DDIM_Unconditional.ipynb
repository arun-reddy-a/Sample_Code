{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from labml_nn.diffusion.stable_diffusion.model.unet_attention import SpatialTransformer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetModel(nn.Module):\n",
    "    \"\"\"\n",
    "    ## U-Net model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, *,\n",
    "            in_channels: int,\n",
    "            out_channels: int,\n",
    "            channels: int,\n",
    "            n_res_blocks: int,\n",
    "            attention_levels: List[int],\n",
    "            channel_multipliers: List[int],\n",
    "            n_heads: int,\n",
    "            tf_layers: int = 1,\n",
    "            d_cond: int = 768):\n",
    "        \"\"\"\n",
    "        :param in_channels: is the number of channels in the input feature map\n",
    "        :param out_channels: is the number of channels in the output feature map\n",
    "        :param channels: is the base channel count for the model\n",
    "        :param n_res_blocks: number of residual blocks at each level\n",
    "        :param attention_levels: are the levels at which attention should be performed\n",
    "        :param channel_multipliers: are the multiplicative factors for number of channels for each level\n",
    "        :param n_heads: is the number of attention heads in the transformers\n",
    "        :param tf_layers: is the number of transformer layers in the transformers\n",
    "        :param d_cond: is the size of the conditional embedding in the transformers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "\n",
    "        # Number of levels\n",
    "        levels = len(channel_multipliers)\n",
    "        # Size time embeddings\n",
    "        d_time_emb = channels * 4\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(channels, d_time_emb),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(d_time_emb, d_time_emb),\n",
    "        )\n",
    "\n",
    "        # Input half of the U-Net\n",
    "        self.input_blocks = nn.ModuleList()\n",
    "        # Initial $3 \\times 3$ convolution that maps the input to `channels`.\n",
    "        # The blocks are wrapped in `TimestepEmbedSequential` module because\n",
    "        # different modules have different forward function signatures;\n",
    "        # for example, convolution only accepts the feature map and\n",
    "        # residual blocks accept the feature map and time embedding.\n",
    "        # `TimestepEmbedSequential` calls them accordingly.\n",
    "        self.input_blocks.append(TimestepEmbedSequential(\n",
    "            nn.Conv2d(in_channels, channels, 3, padding=1)))\n",
    "        # Number of channels at each block in the input half of U-Net\n",
    "        input_block_channels = [channels]\n",
    "        # Number of channels at each level\n",
    "        channels_list = [channels * m for m in channel_multipliers]\n",
    "        # Prepare levels\n",
    "        for i in range(levels):\n",
    "            # Add the residual blocks and attentions\n",
    "            for _ in range(n_res_blocks):\n",
    "                # Residual block maps from previous number of channels to the number of\n",
    "                # channels in the current level\n",
    "                layers = [ResBlock(channels, d_time_emb, out_channels=channels_list[i])]\n",
    "                channels = channels_list[i]\n",
    "                # Add transformer\n",
    "                if i in attention_levels:\n",
    "                    layers.append(SpatialTransformer(channels, n_heads, tf_layers, d_cond))\n",
    "                # Add them to the input half of the U-Net and keep track of the number of channels of\n",
    "                # its output\n",
    "                self.input_blocks.append(TimestepEmbedSequential(*layers))\n",
    "                input_block_channels.append(channels)\n",
    "            # Down sample at all levels except last\n",
    "            if i != levels - 1:\n",
    "                self.input_blocks.append(TimestepEmbedSequential(DownSample(channels)))\n",
    "                input_block_channels.append(channels)\n",
    "\n",
    "        # The middle of the U-Net\n",
    "        self.middle_block = TimestepEmbedSequential(\n",
    "            ResBlock(channels, d_time_emb),\n",
    "            SpatialTransformer(channels, n_heads, tf_layers, d_cond),\n",
    "            ResBlock(channels, d_time_emb),\n",
    "        )\n",
    "\n",
    "        # Second half of the U-Net\n",
    "        self.output_blocks = nn.ModuleList([])\n",
    "        # Prepare levels in reverse order\n",
    "        for i in reversed(range(levels)):\n",
    "            # Add the residual blocks and attentions\n",
    "            for j in range(n_res_blocks + 1):\n",
    "                # Residual block maps from previous number of channels plus the\n",
    "                # skip connections from the input half of U-Net to the number of\n",
    "                # channels in the current level.\n",
    "                layers = [ResBlock(channels + input_block_channels.pop(), d_time_emb, out_channels=channels_list[i])]\n",
    "                channels = channels_list[i]\n",
    "                # Add transformer\n",
    "                if i in attention_levels:\n",
    "                    layers.append(SpatialTransformer(channels, n_heads, tf_layers, d_cond))\n",
    "                # Up-sample at every level after last residual block\n",
    "                # except the last one.\n",
    "                # Note that we are iterating in reverse; i.e. `i == 0` is the last.\n",
    "                if i != 0 and j == n_res_blocks:\n",
    "                    layers.append(UpSample(channels))\n",
    "                # Add to the output half of the U-Net\n",
    "                self.output_blocks.append(TimestepEmbedSequential(*layers))\n",
    "\n",
    "        # Final normalization and $3 \\times 3$ convolution\n",
    "        self.out = nn.Sequential(\n",
    "            normalization(channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(channels, out_channels, 3, padding=1),\n",
    "        )\n",
    "\n",
    "    def time_step_embedding(self, time_steps: torch.Tensor, max_period: int = 10000):\n",
    "        \"\"\"\n",
    "        ## Create sinusoidal time step embeddings\n",
    "\n",
    "        :param time_steps: are the time steps of shape `[batch_size]`\n",
    "        :param max_period: controls the minimum frequency of the embeddings.\n",
    "        \"\"\"\n",
    "        # $\\frac{c}{2}$; half the channels are sin and the other half is cos,\n",
    "        half = self.channels // 2\n",
    "        # $\\frac{1}{10000^{\\frac{2i}{c}}}$\n",
    "        frequencies = torch.exp(\n",
    "            -math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half\n",
    "        ).to(device=time_steps.device)\n",
    "        # $\\frac{t}{10000^{\\frac{2i}{c}}}$\n",
    "        args = time_steps[:, None].float() * frequencies[None]\n",
    "        # $\\cos\\Bigg(\\frac{t}{10000^{\\frac{2i}{c}}}\\Bigg)$ and $\\sin\\Bigg(\\frac{t}{10000^{\\frac{2i}{c}}}\\Bigg)$\n",
    "        return torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, time_steps: torch.Tensor, cond: torch.Tensor):\n",
    "        \"\"\"\n",
    "        :param x: is the input feature map of shape `[batch_size, channels, width, height]`\n",
    "        :param time_steps: are the time steps of shape `[batch_size]`\n",
    "        :param cond: conditioning of shape `[batch_size, n_cond, d_cond]`\n",
    "        \"\"\"\n",
    "        # To store the input half outputs for skip connections\n",
    "        x_input_block = []\n",
    "\n",
    "        # Get time step embeddings\n",
    "        t_emb = self.time_step_embedding(time_steps)\n",
    "        t_emb = self.time_embed(t_emb)\n",
    "\n",
    "        # Input half of the U-Net\n",
    "        for module in self.input_blocks:\n",
    "            x = module(x, t_emb, cond)\n",
    "            x_input_block.append(x)\n",
    "        # Middle of the U-Net\n",
    "        x = self.middle_block(x, t_emb, cond)\n",
    "        # Output half of the U-Net\n",
    "        for module in self.output_blocks:\n",
    "            x = torch.cat([x, x_input_block.pop()], dim=1)\n",
    "            x = module(x, t_emb, cond)\n",
    "\n",
    "        # Final normalization and $3 \\times 3$ convolution\n",
    "        return self.out(x)\n",
    "\n",
    "\n",
    "class TimestepEmbedSequential(nn.Sequential):\n",
    "    \"\"\"\n",
    "    ### Sequential block for modules with different inputs\n",
    "\n",
    "    This sequential module can compose of different modules such as `ResBlock`,\n",
    "    `nn.Conv` and `SpatialTransformer` and calls them with the matching signatures\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x, t_emb, cond=None):\n",
    "        for layer in self:\n",
    "            if isinstance(layer, ResBlock):\n",
    "                x = layer(x, t_emb)\n",
    "            elif isinstance(layer, SpatialTransformer):\n",
    "                x = layer(x, cond)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    \"\"\"\n",
    "    ### Up-sampling layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int):\n",
    "        \"\"\"\n",
    "        :param channels: is the number of channels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # $3 \\times 3$ convolution mapping\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        :param x: is the input feature map with shape `[batch_size, channels, height, width]`\n",
    "        \"\"\"\n",
    "        # Up-sample by a factor of $2$\n",
    "        x = F.interpolate(x, scale_factor=2, mode=\"nearest\")\n",
    "        # Apply convolution\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    \"\"\"\n",
    "    ## Down-sampling layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int):\n",
    "        \"\"\"\n",
    "        :param channels: is the number of channels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # $3 \\times 3$ convolution with stride length of $2$ to down-sample by a factor of $2$\n",
    "        self.op = nn.Conv2d(channels, channels, 3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        :param x: is the input feature map with shape `[batch_size, channels, height, width]`\n",
    "        \"\"\"\n",
    "        # Apply convolution\n",
    "        return self.op(x)\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ## ResNet Block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, d_t_emb: int, *, out_channels=None):\n",
    "        \"\"\"\n",
    "        :param channels: the number of input channels\n",
    "        :param d_t_emb: the size of timestep embeddings\n",
    "        :param out_channels: is the number of out channels. defaults to `channels.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # `out_channels` not specified\n",
    "        if out_channels is None:\n",
    "            out_channels = channels\n",
    "\n",
    "        # First normalization and convolution\n",
    "        self.in_layers = nn.Sequential(\n",
    "            normalization(channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(channels, out_channels, 3, padding=1),\n",
    "        )\n",
    "\n",
    "        # Time step embeddings\n",
    "        self.emb_layers = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(d_t_emb, out_channels),\n",
    "        )\n",
    "        # Final convolution layer\n",
    "        self.out_layers = nn.Sequential(\n",
    "            normalization(out_channels),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(0.),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        )\n",
    "\n",
    "        # `channels` to `out_channels` mapping layer for residual connection\n",
    "        if out_channels == channels:\n",
    "            self.skip_connection = nn.Identity()\n",
    "        else:\n",
    "            self.skip_connection = nn.Conv2d(channels, out_channels, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t_emb: torch.Tensor):\n",
    "        \"\"\"\n",
    "        :param x: is the input feature map with shape `[batch_size, channels, height, width]`\n",
    "        :param t_emb: is the time step embeddings of shape `[batch_size, d_t_emb]`\n",
    "        \"\"\"\n",
    "        # Initial convolution\n",
    "        h = self.in_layers(x)\n",
    "        # Time step embeddings\n",
    "        t_emb = self.emb_layers(t_emb).type(h.dtype)\n",
    "        # Add time step embeddings\n",
    "        h = h + t_emb[:, :, None, None]\n",
    "        # Final convolution\n",
    "        h = self.out_layers(h)\n",
    "        # Add skip connection\n",
    "        return self.skip_connection(x) + h\n",
    "\n",
    "\n",
    "class GroupNorm32(nn.GroupNorm):\n",
    "    \"\"\"\n",
    "    ### Group normalization with float32 casting\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return super().forward(x.float()).type(x.dtype)\n",
    "\n",
    "\n",
    "def normalization(channels):\n",
    "    \"\"\"\n",
    "    ### Group normalization\n",
    "\n",
    "    This is a helper function, with fixed number of groups..\n",
    "    \"\"\"\n",
    "    return GroupNorm32(32, channels)\n",
    "\n",
    "\n",
    "def _test_time_embeddings():\n",
    "    \"\"\"\n",
    "    Test sinusoidal time step embeddings\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    m = UNetModel(in_channels=1, out_channels=1, channels=320, n_res_blocks=1, attention_levels=[],\n",
    "                  channel_multipliers=[],\n",
    "                  n_heads=1, tf_layers=1, d_cond=1)\n",
    "    te = m.time_step_embedding(torch.arange(0, 1000))\n",
    "    plt.plot(np.arange(1000), te[:, [50, 100, 190, 260]].numpy())\n",
    "    plt.legend([\"dim %d\" % p for p in [50, 100, 190, 260]])\n",
    "    plt.title(\"Time embeddings\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 1\n",
    "out_channels = 1\n",
    "channels = 32\n",
    "n_res_block = 2\n",
    "attention_levels = [1,2]\n",
    "channel_multipliers = [2, 3]\n",
    "n_heads = 2\n",
    "tf_layers = 1\n",
    "d_cond = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNoiseScheduler:\n",
    "    r\"\"\"\n",
    "    Class for the linear noise scheduler that is used in DDPM.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_timesteps, beta_start, beta_end):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        \n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps).to(device)\n",
    "        self.alphas = 1. - self.betas\n",
    "        self.alpha_cum_prod = torch.cumprod(self.alphas, dim=0).to(device)\n",
    "        self.sqrt_alpha_cum_prod = torch.sqrt(self.alpha_cum_prod).to(device)\n",
    "        self.sqrt_one_minus_alpha_cum_prod = torch.sqrt(1 - self.alpha_cum_prod).to(device)\n",
    "        \n",
    "    def add_noise(self, original, noise, t):\n",
    "        r\"\"\"\n",
    "        Forward method for diffusion\n",
    "        :param original: Image on which noise is to be applied\n",
    "        :param noise: Random Noise Tensor (from normal dist)\n",
    "        :param t: timestep of the forward process of shape -> (B,)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        original_shape = original.shape\n",
    "        batch_size = original_shape[0]\n",
    "        \n",
    "        sqrt_alpha_cum_prod = self.sqrt_alpha_cum_prod[t].reshape(batch_size)\n",
    "        sqrt_one_minus_alpha_cum_prod = self.sqrt_one_minus_alpha_cum_prod[t].reshape(batch_size)\n",
    "        \n",
    "        # Reshape till (B,) becomes (B,1,1,1) if image is (B,C,H,W)\n",
    "        for _ in range(len(original_shape)-1):\n",
    "            sqrt_alpha_cum_prod = sqrt_alpha_cum_prod.unsqueeze(-1)\n",
    "        for _ in range(len(original_shape)-1):\n",
    "            sqrt_one_minus_alpha_cum_prod = sqrt_one_minus_alpha_cum_prod.unsqueeze(-1)\n",
    "\n",
    "        # Apply and Return Forward process equation\n",
    "        return (sqrt_alpha_cum_prod.to(original.device) * original\n",
    "                + sqrt_one_minus_alpha_cum_prod.to(original.device) * noise)\n",
    "        \n",
    "    def sample_prev_timestep(self, xt, noise_pred, t):\n",
    "        r\"\"\"\n",
    "            Use the noise prediction by model to get\n",
    "            xt-1 using xt and the nosie predicted\n",
    "        :param xt: current timestep sample\n",
    "        :param noise_pred: model noise prediction\n",
    "        :param t: current timestep we are at\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        x0 = (xt - (self.sqrt_one_minus_alpha_cum_prod[t] * noise_pred)) / torch.sqrt(self.alpha_cum_prod[t])\n",
    "        x0 = torch.clamp(x0, -1., 1.)\n",
    "\n",
    "        mean = xt - ((self.betas[t])*noise_pred)/(self.sqrt_one_minus_alpha_cum_prod[t])\n",
    "        mean = mean / torch.sqrt(self.alphas[t])\n",
    "        \n",
    "        if t == 0:\n",
    "            return mean, mean\n",
    "        else:\n",
    "            variance = (1-self.alpha_cum_prod[t-1]) / (1.0 - self.alpha_cum_prod[t])\n",
    "            variance = variance * self.betas[t]\n",
    "            sigma = variance ** 0.5\n",
    "            z = torch.randn(xt.shape).to(xt.device)\n",
    "            \n",
    "            # OR\n",
    "            # variance = self.betas[t]\n",
    "            # sigma = variance ** 0.5\n",
    "            # z = torch.randn(xt.shape).to(xt.device)\n",
    "            return mean + sigma*z, x0\n",
    "\n",
    "    def sample_prev_timestep_ddim (self, xt, noise_pred, t, prev_t):\n",
    "\n",
    "        x0 = (xt - self.sqrt_one_minus_alpha_cum_prod[t]*noise_pred) / torch.sqrt(self.alpha_cum_prod[t])\n",
    "        x0 = torch.clamp(x0, -1., 1.)\n",
    "        xt_prev = self.sqrt_alpha_cum_prod[prev_t] * x0 + self.sqrt_one_minus_alpha_cum_prod[prev_t]*noise_pred\n",
    "        return xt_prev, x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_net_model = UNetModel(in_channels=in_channels, out_channels=out_channels, channels=channels, n_res_blocks=n_res_block,\n",
    "                        attention_levels=attention_levels, channel_multipliers=channel_multipliers, n_heads=n_heads, \n",
    "                        tf_layers=tf_layers, d_cond=d_cond).to(device)\n",
    "ls = LinearNoiseScheduler(1000, 1e-4, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): DownSample(\n",
       "        (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GeGLU(\n",
       "                  (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GeGLU(\n",
       "                  (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): SpatialTransformer(\n",
       "      (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "      (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0): BasicTransformerBlock(\n",
       "          (attn1): CrossAttention(\n",
       "            (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "            (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "            (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn2): CrossAttention(\n",
       "            (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (ff): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): GeGLU(\n",
       "                (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (output_blocks): ModuleList(\n",
       "    (0-1): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GeGLU(\n",
       "                  (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 160, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(160, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(160, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GeGLU(\n",
       "                  (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): UpSample(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 160, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(160, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_net_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reddyanugu/miniconda3/envs/pytorch/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/reddyanugu/miniconda3/envs/pytorch/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# load mnist dataset and make dataloader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "optimizer = torch.optim.Adam(u_net_model.parameters(), lr=0.0001)\n",
    "loss_array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for batch in trainloader:\n",
    "        im = batch[0].to(device)\n",
    "        t = torch.randint(0, 1000, (32,)).to(device)\n",
    "        cond = torch.zeros(32, 1, 768).to(device)\n",
    "        noise = torch.randn(32, 1, 28, 28).to(device)\n",
    "        xt = ls.add_noise(im, noise, t).to(device)\n",
    "        noise_pred = u_net_model(xt, t, cond)\n",
    "        loss = F.mse_loss(noise_pred, noise)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_array.append(loss.item())\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 32, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): DownSample(\n",
       "        (op): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GeGLU(\n",
       "                  (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GeGLU(\n",
       "                  (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): SpatialTransformer(\n",
       "      (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "      (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0): BasicTransformerBlock(\n",
       "          (attn1): CrossAttention(\n",
       "            (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "            (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "            (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn2): CrossAttention(\n",
       "            (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "            (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "            (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "            (to_out): Sequential(\n",
       "              (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (ff): FeedForward(\n",
       "            (net): Sequential(\n",
       "              (0): GeGLU(\n",
       "                (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "              )\n",
       "              (1): Dropout(p=0.0, inplace=False)\n",
       "              (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (output_blocks): ModuleList(\n",
       "    (0-1): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 192, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GeGLU(\n",
       "                  (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 160, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(160, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=96, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(160, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): SpatialTransformer(\n",
       "        (norm): GroupNorm(32, 96, eps=1e-06, affine=True)\n",
       "        (proj_in): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (transformer_blocks): ModuleList(\n",
       "          (0): BasicTransformerBlock(\n",
       "            (attn1): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn2): CrossAttention(\n",
       "              (to_q): Linear(in_features=96, out_features=96, bias=False)\n",
       "              (to_k): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_v): Linear(in_features=768, out_features=96, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=96, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (ff): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): GeGLU(\n",
       "                  (proj): Linear(in_features=96, out_features=768, bias=True)\n",
       "                )\n",
       "                (1): Dropout(p=0.0, inplace=False)\n",
       "                (2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (norm3): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (proj_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (2): UpSample(\n",
       "        (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 160, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(160, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 96, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 64, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_net_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the parameters of u_net_model\n",
    "torch.save(u_net_model.state_dict(), 'u_net_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_net_model.load_state_dict(torch.load('aq_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpu_memory_usage():\n",
    "    result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits'],\n",
    "                            stdout=subprocess.PIPE, text=True)\n",
    "    \n",
    "    # The output will be in the form 'memory.used\\n1234\\n5678\\n...'\n",
    "    # Extract the numeric values\n",
    "    memory_used_values = [int(value) for value in result.stdout.strip().split('\\n')[1:]]\n",
    "\n",
    "    return memory_used_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image (ddim=False, end_timestep=999, skip=10):\n",
    "    # memory_used_values = get_gpu_memory_usage()\n",
    "    # print(\"GPU Memory Usage:\", memory_used_values[1])\n",
    "    xt = torch.randn(100, 1, 28, 28).to(device)\n",
    "    cond = torch.zeros(100, 1, 768).to(device)\n",
    "    # memory_used_values = get_gpu_memory_usage()\n",
    "    # print(\"GPU Memory Usage:\", memory_used_values[1])\n",
    "    if ddim:\n",
    "        timestamps = torch.arange(end_timestep, 0, -1*skip)[:, None].to(device)\n",
    "    else:\n",
    "        timestamps = torch.arange(end_timestep, 0, -1)[:, None].to(device)\n",
    "    for t in tqdm(timestamps):\n",
    "        index = torch.where(timestamps == t)[0]\n",
    "        with torch.no_grad():\n",
    "            noise_pred = u_net_model(xt, t, cond)\n",
    "            if ddim:\n",
    "                if (index + 1) != len(timestamps):\n",
    "                    xt, x0 = ls.sample_prev_timestep_ddim(xt, noise_pred, t, timestamps[index+1])\n",
    "            else:\n",
    "                xt, x0 = ls.sample_prev_timestep(xt, noise_pred, t)\n",
    "    return xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in trainloader:\n",
    "    real_images = x\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 999/999 [00:17<00:00, 56.51it/s]\n"
     ]
    }
   ],
   "source": [
    "images = generate_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:08<00:00, 59.13it/s]\n"
     ]
    }
   ],
   "source": [
    "images_ddim = generate_image(ddim=True, end_timestep=999, skip=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a 3x3 grid of subplots\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(8, 8))\n",
    "\n",
    "# Iterate through the images and plot them on the subplots\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(images[i][0, :, :].detach().cpu().numpy(), cmap='gray')\n",
    "    ax.axis('off')  # Hide axes for better visualization\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a 3x3 grid of subplots\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(8, 8))\n",
    "\n",
    "# Iterate through the images and plot them on the subplots\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(images_ddim[i][0, :, :].detach().cpu().numpy(), cmap='gray')\n",
    "    ax.axis('off')  # Hide axes for better visualization\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 28, 28])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_ddim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_real = real_images.squeeze().reshape(-1, 28*28).detach().cpu().mean(axis=0).numpy()\n",
    "mean_images = images.squeeze().reshape(-1, 28*28).detach().cpu().mean(axis=0).numpy()\n",
    "mean_images_ddim = images_ddim.squeeze().reshape(-1, 28*28).detach().cpu().mean(axis=0).numpy()\n",
    "\n",
    "cov_real = np.cov(real_images.squeeze().reshape(-1, 28*28).detach().cpu(), rowvar=False)\n",
    "cov_images = np.cov(images.squeeze().reshape(-1, 28*28).detach().cpu(), rowvar=False)\n",
    "cov_images_ddim = np.cov(images_ddim.squeeze().reshape(-1, 28*28).detach().cpu(), rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fid (mu_1, mu_2, cov_1, cov2):\n",
    "    ssdiff = np.sum((mu_1 - mu_2)**2.0)\n",
    "    covmean = sqrtm(cov_1.dot(cov2))\n",
    "    if np.iscomplexobj(covmean):\n",
    "        covmean = covmean.real\n",
    "    fid = ssdiff + np.trace(cov_1 + cov2 - 2.0 * covmean)\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.81463346164411"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_fid(mean_real, mean_images, cov_real, cov_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.504593738400914"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_fid(mean_real, mean_images_ddim, cov_real, cov_images_ddim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
